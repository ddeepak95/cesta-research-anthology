[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Nicole Coleman,  \n        Felicia Smith,      Tracy Wei,   Anabelle Colmenares  \n      \n      \n    \n    \n      \n    \n  \n\n\n  \n    \n      \n      \n        Giovanna Ceserani,      Raagavi Ragothaman  \n      \n      \n    \n    \n      \n    \n  \n\n\nNo matching items"
  },
  {
    "objectID": "index.html#edition",
    "href": "index.html#edition",
    "title": "Home",
    "section": "",
    "text": "Nicole Coleman,  \n        Felicia Smith,      Tracy Wei,   Anabelle Colmenares  \n      \n      \n    \n    \n      \n    \n  \n\n\n  \n    \n      \n      \n        Giovanna Ceserani,      Raagavi Ragothaman  \n      \n      \n    \n    \n      \n    \n  \n\n\nNo matching items"
  },
  {
    "objectID": "editions/2023/index.html",
    "href": "editions/2023/index.html",
    "title": "CESTA Research Anthology 2023 Edition",
    "section": "",
    "text": "Grand Tour Project\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nKnow Systemic Racism\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "editions/index.html",
    "href": "editions/index.html",
    "title": "Editions",
    "section": "",
    "text": "CESTA Research Anthology 2023 Edition\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "docs/index.html",
    "href": "docs/index.html",
    "title": "Developer Documentation",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "docs/index.html#for-admins",
    "href": "docs/index.html#for-admins",
    "title": "Developer Documentation",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "docs/setting-up-the-submodule/index.html",
    "href": "docs/setting-up-the-submodule/index.html",
    "title": "Setting up the sub-module",
    "section": "",
    "text": "In CESTA Anthology website, each edition of the Anthology is a separate git repository which is then added to the main repository as a sub-module. This document explains how to setup sub-module and then connect it to the main repository."
  },
  {
    "objectID": "docs/setting-up-the-submodule/index.html#prerequisite",
    "href": "docs/setting-up-the-submodule/index.html#prerequisite",
    "title": "Setting up the sub-module",
    "section": "Prerequisite",
    "text": "Prerequisite\n\nQuarto\nGit\nVS Code (Preferable)"
  },
  {
    "objectID": "docs/setting-up-the-submodule/index.html#setting-up-a-sub-module",
    "href": "docs/setting-up-the-submodule/index.html#setting-up-a-sub-module",
    "title": "Setting up the sub-module",
    "section": "Setting up a sub-module",
    "text": "Setting up a sub-module\n\nFork the template repository for the new edition of Anthology\nOpen the repository in your IDE (Preferably VSCode). The root directory of the repository should be the root directory of the project in your IDE.\nCreate a virtual environment with python3 -m venv .venv while being in the root directory of the repository\nActivate the virtual environment\n\nOn Windows: .venv\\Scripts\\Activate\nOn Mac/Linux: source .venv/bin/activate\n\nInstall the dependencies with pip install -r requirements.txt inside the virtual environment\nRun the preview with command quarto preview\nIf everything is set, you should be able to see the preview page."
  },
  {
    "objectID": "docs/setting-up-the-submodule/index.html#seeing-the-preview-on-cloud",
    "href": "docs/setting-up-the-submodule/index.html#seeing-the-preview-on-cloud",
    "title": "Setting up the sub-module",
    "section": "Seeing the preview on cloud",
    "text": "Seeing the preview on cloud\nFollow the instructions in this page https://quarto.org/docs/publishing/github-pages.html#publish-command to publish the preview website on the Github Pages."
  },
  {
    "objectID": "docs/setting-up-the-submodule/index.html#linking-the-submodule-to-the-parent-repository",
    "href": "docs/setting-up-the-submodule/index.html#linking-the-submodule-to-the-parent-repository",
    "title": "Setting up the sub-module",
    "section": "Linking the submodule to the parent repository",
    "text": "Linking the submodule to the parent repository\n\nOpen the root directory of the parent CESTA Anthology repository in terminal\nRun the command to add the submodule git submodule add https://github.com/another_username/cesta_submodule_repository.git src/editions/{year}. Replace year with the year of the edition.\n\nFor example, if repository link is https://github.com/ddeepak95/cesta_2024 and edition is 2024, then the code would be git submodule add https://github.com/ddeepak95/cesta_2024.git src/editions/2024\n\nInitialize and update the submodule git submodule update --init --recursive\nYou are all done now you can reference the files in the submodule in the parent repository!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Whatttttt"
  },
  {
    "objectID": "about.html#ehllo",
    "href": "about.html#ehllo",
    "title": "About",
    "section": "",
    "text": "Whatttttt"
  },
  {
    "objectID": "editions/2023/grand-tour-project/index.html",
    "href": "editions/2023/grand-tour-project/index.html",
    "title": "Grand Tour Project",
    "section": "",
    "text": "In the 18th century, thousands of Northern Europeans traveled to Italy for a journey of cultural and symbolic capital that they called the Grand Tour. These travels were a formative institution of modernity and contributed to a massive reimagining of politics and the arts, ideas about leisure, the market for culture, and the practices of professionalism. Since 2008, the Grand Tour Project (grandtour.stanford.edu) has generated digital tools, analyses, and visualizations to bring us closer to the diverse travelers who collectively represent 18th-century travel to Italy. We have been digitizing and enhancing John Ingamells’ Dictionary of British and Irish Travelers to Italy 1701-1800 to create a searchable database of more than six thousand entries. This past year the project’s focus has been on preparing this interactive database and an accompanying digital volume for publication with the title A World Made by Travel: The Digital Grand Tour for the Stanford University Press Digital Series. CESTA intern alumni Ashwin Ramaswami and Ryan Tan returned to the project to work on this exciting phase as we refined both development and design to satisfy the press’s guidelines, anonymous reviewers’ comments, digital accessibility, and best practices for digital sustainability and preservation. Raagavi Ragothaman, a CS coterm master’s student, also contributed in crucial ways, focusing on interactivity features and data visualizations.\nFor the project’s publication, we wanted to communicate immediately and clearly how the data for the more than six thousand travelers in the database is not only incomplete but also that this incompleteness is unevenly distributed. For any one traveler, we might have a lot of data about their journey but very little about their life—maybe not even their date of birth. We used the parallel sets visualization (originally created using Titanic passengers’ data) to convey this information showing at once the correlations among five dimensions across the entire database: 1) whether we had data about travelers’ dates of birth and death, 2) about their occupation and education, 3) the gender of the travelers, 4) how many data points (visits) we had for their journeys, and, finally, 5) whether the travelers’ entries were found in the original Dictionary, or if we newly created their entries in the course of the project as we recovered forgotten travelers.\n\n\nCode\nd3 = require(\"d3@6\", \"d3-sankey@0.12\")\n\n\n\n\n\n\n\n\n\nCode\nwidth = 975\n\n\n\n\n\n\n\n\n\nCode\nheight = 720\n\n\n\n\n\n\n\n\n\nCode\nkeys = [\"gender\", \"dates\", \"origin\", \"events\", \"travels\"]\n\n\n\n\n\n\n\n\n\nCode\ndata = d3.csvParse(await FileAttachment(\"data/data_new_gte (2)@2.csv\").text(), d3.autoType)\n\n\n\n\n\n\n\n\n\nCode\nsankey = d3.sankey()\n    .nodeSort(null)\n    .linkSort(null)\n    .nodeWidth(4)\n    .nodePadding(20)\n    .extent([[0, 5], [width, height - 5]])\n\n\n\n\n\n\n\n\n\nCode\ncolorScale = d3.scaleOrdinal([\"Male\", \"Female\"], [\"#ACD1AF\",\"#FFC000\"]).unknown(\"#ccc\")\n\n\n\n\n\n\n\n\n\nCode\ngraph = {\n  let index = -1;\n  const nodes = [];\n  const nodeByKey = new Map;\n  const indexByKey = new Map;\n  const links = [];\n\n  for (const k of keys.slice(1)) {\n    for (const d of data) {\n      const key = JSON.stringify([k, d[k]]);\n      if (nodeByKey.has(key)) continue;\n      const node = {name: d[k], key: k};\n      nodes.push(node);\n      nodeByKey.set(key, node);\n      indexByKey.set(key, ++index);\n    }\n  }\n\n  for (let i = 2; i &lt; keys.length; ++i) {\n    const a = keys[i - 1];\n    const b = keys[i];\n    const prefix = keys.slice(0, i + 1);\n    const linkByKey = new Map;\n    for (const d of data) {\n      const names = prefix.map(k =&gt; d[k]);\n      const key = JSON.stringify(names);\n      const value = d.value || 1;\n      let link = linkByKey.get(key);\n      if (link) { link.value += value; continue; }\n      link = {\n        source: indexByKey.get(JSON.stringify([a, d[a]])),\n        target: indexByKey.get(JSON.stringify([b, d[b]])),\n        names,\n        value\n      };\n      links.push(link);\n      linkByKey.set(key, link);\n    }\n  }\n\n  return {nodes, links};\n}\n\n\n\n\n\n\n\n\n\nCode\nchart = {\n  const axis_name = {\n    \"dates\": \"Has biographical dates?\",\n    \"origin\": \"Source of the entry\",\n    \"events\": \"Has occupation/education data?\",\n    \"travels\": \"No. of visits to places\"\n  }\n  const colorAxisLabels = {\n  \"Male\": \"Men\",\n  \"Female\": \"Women\",\n  \"Unknown\": \"Unknown\"\n};\n  \n  const svg = d3.create(\"svg\")\n      .attr(\"viewBox\", [0, -15, width, height+45]);\n\n  const { nodes, links } = sankey({\n    nodes: graph.nodes.map(d =&gt; Object.assign({}, d)),\n    links: graph.links.map(d =&gt; Object.assign({}, d))\n  });\n\n  const link = svg.append(\"g\")\n    .attr(\"fill\", \"none\")\n    .selectAll(\"g\")\n    .data(links)\n    .join(\"g\");\n\n  // Set up the links\n  link.append(\"path\")\n    .attr(\"d\", d3.sankeyLinkHorizontal())\n    .attr(\"stroke\", d =&gt; colorScale(d.names[0]))\n    .attr(\"stroke-width\", d =&gt; d.width)\n    .style(\"mix-blend-mode\", \"multiply\")\n    .style(\"opacity\", 1) // Set initial opacity to 1\n\nlink.append(\"title\")\n  .text(d =&gt; `${d.names.join(\" → \")}\\n${d.value.toLocaleString()}`);\n\n// Add color axis label\n\n  function changeLinks(link, d) {\n    link.style(\"opacity\", linkData =&gt; (linkData === d ? 1 : 0.2));\n    // Set opacity of ancestors and children links to 1\n    setAncestorLinksOpacity(d, 1);\n    setDescendantLinksOpacity(d, 1);\n\n  }\n\n  // Event listeners for link hover\n  link.on(\"mouseover\", function (event, d) {\n    changeLinks(link, d);\n\n  })\n    .on(\"mouseout\", function () {\n      link.style(\"opacity\", 1);\n    });\n\n  // Function to set opacity of ancestor links\n  function setAncestorLinksOpacity(d, opacity) {\n    link.filter(linkData =&gt; isAncestorLink(linkData, d)).style(\"opacity\", opacity);\n  }\n\n  // Function to set opacity of descendant links\n  function setDescendantLinksOpacity(d, opacity) {\n    link.filter(linkData =&gt; isDescendantLink(linkData, d)).style(\"opacity\", opacity);\n  }\n\n  // Function to check if link is an ancestor link\n  function isAncestorLink(linkData, d) {\n    let flag = true\n    for (let i = 0; i &lt; linkData.names.length; ++i) {\n      if (linkData.names[i] !== d.names[i]) \n        flag = false;\n    }\n    return flag;\n  }\n\n  // Function to check if link is a descendant link\n  function isDescendantLink(linkData, d) {\n    let flag = true\n    for (let i = 0; i &lt; d.names.length; ++i) {\n      if (linkData.names[i] !== d.names[i]) \n        flag = false;\n    }\n    return flag;\n  }\n\n  svg.append(\"g\")\n    .selectAll(\"rect\")\n    .data(nodes)\n    .join(\"rect\")\n    .attr(\"x\", d =&gt; d.x0)\n    .attr(\"y\", d =&gt; d.y0)\n    .attr(\"height\", d =&gt; d.y1 - d.y0)\n    .attr(\"width\", d =&gt; d.x1 - d.x0)\n    .append(\"title\")\n    .text(d =&gt; `${d.name}\\n${d.value.toLocaleString()}`);\n  \n  \n  svg.append(\"g\")\n    .selectAll(\"legend\")\n    .data(Object.keys(colorAxisLabels))\n    .join(\"rect\")\n    .attr(\"fill\", d =&gt; colorScale(d))\n    .attr(\"opacity\", 0.4)\n    .attr(\"x\", function(d,i){ return (width / 3 * i) + ((width/6)-50)})\n    .attr(\"y\", d =&gt; height)\n    .attr('rx', 5)\n    .attr('z', -100)\n    .attr(\"height\", 22)\n    .attr(\"width\", 100)\n    \n  .join('g')\n\n    svg.append(\"g\")\n    .style(\"font\", \"13px serif\")\n    .style(\"font-weight\", \"bold\")\n    .selectAll(\"text\")\n    .data(Object.keys(colorAxisLabels))\n    .attr(\"class\", \"legend-item\")\n    .join(\"text\")\n    .attr(\"x\", function(d,i){ return (width / 3 * i) + (width/6)})\n    .attr(\"y\", d =&gt; height+10)\n    .attr(\"dy\", \"0.35em\")\n    .attr(\"text-anchor\", \"middle\")\n    .text(d =&gt; colorAxisLabels[d])\n\n\n  svg.append(\"g\")\n    .style(\"font\", \"13px serif\")\n    .style(\"font-weight\", \"bold\")\n    .selectAll(\"text\")\n    .data(nodes)\n    .join(\"text\")\n    .attr(\"x\", d =&gt; d.x0 &lt; width / 2 ? d.x1 + 6 : d.x0 - 6)\n    .attr(\"y\", d =&gt; -10)\n    .attr(\"dy\", \"0.35em\")\n    .attr(\"text-anchor\", d =&gt; d.key == 'origin' || d.key == 'events' ? \"middle\" :  d.key == 'dates' ? \"start\": \"end\" )\n    .text(d =&gt; axis_name[d.key])\n\n  svg.append(\"g\")\n    .style(\"font\", \"10px sans-serif\")\n    .selectAll(\"text\")\n    .data(nodes)\n    .join(\"text\")\n    .attr(\"x\", d =&gt; d.x0 &lt; width / 2 ? d.x1 + 6 : d.x0 - 6)\n    .attr(\"y\", d =&gt; (d.y1 + d.y0) / 2)\n    .attr(\"dy\", \"0.35em\")\n    .attr(\"text-anchor\", d =&gt; d.x0 &lt; width / 2 ? \"start\" : \"end\")\n    .text(d =&gt; d.name)\n    .append(\"tspan\")\n    .attr(\"fill-opacity\", 0.7)\n    .text(d =&gt; ` ${d.value.toLocaleString()}`);\n\n  return svg.node();\n}\n\n\n\n\n\n\n\nThe parallel sets offer an interactive visualization: by hovering over the various curved sections, the reader can appreciate how specific dimensions correlate in the database. This screenshot shows that by hovering on the yellow fine curved line in the last panel, you see that there are twelve women in the database for whom we have both birth and death dates, who had entries in the original Dictionary, and who are among the 2% of travelers for whom we have data for between 26 and 74 visits during their journeys.\n Raagavi in a data analysis and visualization session discussing an early version of the parallel sets visualization with digital design professor Michele Graffieti, who visited CESTA last spring from DensityDesign Lab at the Italian Politecnico University of Milan—the best work happens collaboratively!"
  },
  {
    "objectID": "editions/2023/grand-tour-project/index.html#project-description",
    "href": "editions/2023/grand-tour-project/index.html#project-description",
    "title": "Grand Tour Project",
    "section": "",
    "text": "In the 18th century, thousands of Northern Europeans traveled to Italy for a journey of cultural and symbolic capital that they called the Grand Tour. These travels were a formative institution of modernity and contributed to a massive reimagining of politics and the arts, ideas about leisure, the market for culture, and the practices of professionalism. Since 2008, the Grand Tour Project (grandtour.stanford.edu) has generated digital tools, analyses, and visualizations to bring us closer to the diverse travelers who collectively represent 18th-century travel to Italy. We have been digitizing and enhancing John Ingamells’ Dictionary of British and Irish Travelers to Italy 1701-1800 to create a searchable database of more than six thousand entries. This past year the project’s focus has been on preparing this interactive database and an accompanying digital volume for publication with the title A World Made by Travel: The Digital Grand Tour for the Stanford University Press Digital Series. CESTA intern alumni Ashwin Ramaswami and Ryan Tan returned to the project to work on this exciting phase as we refined both development and design to satisfy the press’s guidelines, anonymous reviewers’ comments, digital accessibility, and best practices for digital sustainability and preservation. Raagavi Ragothaman, a CS coterm master’s student, also contributed in crucial ways, focusing on interactivity features and data visualizations.\nFor the project’s publication, we wanted to communicate immediately and clearly how the data for the more than six thousand travelers in the database is not only incomplete but also that this incompleteness is unevenly distributed. For any one traveler, we might have a lot of data about their journey but very little about their life—maybe not even their date of birth. We used the parallel sets visualization (originally created using Titanic passengers’ data) to convey this information showing at once the correlations among five dimensions across the entire database: 1) whether we had data about travelers’ dates of birth and death, 2) about their occupation and education, 3) the gender of the travelers, 4) how many data points (visits) we had for their journeys, and, finally, 5) whether the travelers’ entries were found in the original Dictionary, or if we newly created their entries in the course of the project as we recovered forgotten travelers.\n\n\nCode\nd3 = require(\"d3@6\", \"d3-sankey@0.12\")\n\n\n\n\n\n\n\n\n\nCode\nwidth = 975\n\n\n\n\n\n\n\n\n\nCode\nheight = 720\n\n\n\n\n\n\n\n\n\nCode\nkeys = [\"gender\", \"dates\", \"origin\", \"events\", \"travels\"]\n\n\n\n\n\n\n\n\n\nCode\ndata = d3.csvParse(await FileAttachment(\"data/data_new_gte (2)@2.csv\").text(), d3.autoType)\n\n\n\n\n\n\n\n\n\nCode\nsankey = d3.sankey()\n    .nodeSort(null)\n    .linkSort(null)\n    .nodeWidth(4)\n    .nodePadding(20)\n    .extent([[0, 5], [width, height - 5]])\n\n\n\n\n\n\n\n\n\nCode\ncolorScale = d3.scaleOrdinal([\"Male\", \"Female\"], [\"#ACD1AF\",\"#FFC000\"]).unknown(\"#ccc\")\n\n\n\n\n\n\n\n\n\nCode\ngraph = {\n  let index = -1;\n  const nodes = [];\n  const nodeByKey = new Map;\n  const indexByKey = new Map;\n  const links = [];\n\n  for (const k of keys.slice(1)) {\n    for (const d of data) {\n      const key = JSON.stringify([k, d[k]]);\n      if (nodeByKey.has(key)) continue;\n      const node = {name: d[k], key: k};\n      nodes.push(node);\n      nodeByKey.set(key, node);\n      indexByKey.set(key, ++index);\n    }\n  }\n\n  for (let i = 2; i &lt; keys.length; ++i) {\n    const a = keys[i - 1];\n    const b = keys[i];\n    const prefix = keys.slice(0, i + 1);\n    const linkByKey = new Map;\n    for (const d of data) {\n      const names = prefix.map(k =&gt; d[k]);\n      const key = JSON.stringify(names);\n      const value = d.value || 1;\n      let link = linkByKey.get(key);\n      if (link) { link.value += value; continue; }\n      link = {\n        source: indexByKey.get(JSON.stringify([a, d[a]])),\n        target: indexByKey.get(JSON.stringify([b, d[b]])),\n        names,\n        value\n      };\n      links.push(link);\n      linkByKey.set(key, link);\n    }\n  }\n\n  return {nodes, links};\n}\n\n\n\n\n\n\n\n\n\nCode\nchart = {\n  const axis_name = {\n    \"dates\": \"Has biographical dates?\",\n    \"origin\": \"Source of the entry\",\n    \"events\": \"Has occupation/education data?\",\n    \"travels\": \"No. of visits to places\"\n  }\n  const colorAxisLabels = {\n  \"Male\": \"Men\",\n  \"Female\": \"Women\",\n  \"Unknown\": \"Unknown\"\n};\n  \n  const svg = d3.create(\"svg\")\n      .attr(\"viewBox\", [0, -15, width, height+45]);\n\n  const { nodes, links } = sankey({\n    nodes: graph.nodes.map(d =&gt; Object.assign({}, d)),\n    links: graph.links.map(d =&gt; Object.assign({}, d))\n  });\n\n  const link = svg.append(\"g\")\n    .attr(\"fill\", \"none\")\n    .selectAll(\"g\")\n    .data(links)\n    .join(\"g\");\n\n  // Set up the links\n  link.append(\"path\")\n    .attr(\"d\", d3.sankeyLinkHorizontal())\n    .attr(\"stroke\", d =&gt; colorScale(d.names[0]))\n    .attr(\"stroke-width\", d =&gt; d.width)\n    .style(\"mix-blend-mode\", \"multiply\")\n    .style(\"opacity\", 1) // Set initial opacity to 1\n\nlink.append(\"title\")\n  .text(d =&gt; `${d.names.join(\" → \")}\\n${d.value.toLocaleString()}`);\n\n// Add color axis label\n\n  function changeLinks(link, d) {\n    link.style(\"opacity\", linkData =&gt; (linkData === d ? 1 : 0.2));\n    // Set opacity of ancestors and children links to 1\n    setAncestorLinksOpacity(d, 1);\n    setDescendantLinksOpacity(d, 1);\n\n  }\n\n  // Event listeners for link hover\n  link.on(\"mouseover\", function (event, d) {\n    changeLinks(link, d);\n\n  })\n    .on(\"mouseout\", function () {\n      link.style(\"opacity\", 1);\n    });\n\n  // Function to set opacity of ancestor links\n  function setAncestorLinksOpacity(d, opacity) {\n    link.filter(linkData =&gt; isAncestorLink(linkData, d)).style(\"opacity\", opacity);\n  }\n\n  // Function to set opacity of descendant links\n  function setDescendantLinksOpacity(d, opacity) {\n    link.filter(linkData =&gt; isDescendantLink(linkData, d)).style(\"opacity\", opacity);\n  }\n\n  // Function to check if link is an ancestor link\n  function isAncestorLink(linkData, d) {\n    let flag = true\n    for (let i = 0; i &lt; linkData.names.length; ++i) {\n      if (linkData.names[i] !== d.names[i]) \n        flag = false;\n    }\n    return flag;\n  }\n\n  // Function to check if link is a descendant link\n  function isDescendantLink(linkData, d) {\n    let flag = true\n    for (let i = 0; i &lt; d.names.length; ++i) {\n      if (linkData.names[i] !== d.names[i]) \n        flag = false;\n    }\n    return flag;\n  }\n\n  svg.append(\"g\")\n    .selectAll(\"rect\")\n    .data(nodes)\n    .join(\"rect\")\n    .attr(\"x\", d =&gt; d.x0)\n    .attr(\"y\", d =&gt; d.y0)\n    .attr(\"height\", d =&gt; d.y1 - d.y0)\n    .attr(\"width\", d =&gt; d.x1 - d.x0)\n    .append(\"title\")\n    .text(d =&gt; `${d.name}\\n${d.value.toLocaleString()}`);\n  \n  \n  svg.append(\"g\")\n    .selectAll(\"legend\")\n    .data(Object.keys(colorAxisLabels))\n    .join(\"rect\")\n    .attr(\"fill\", d =&gt; colorScale(d))\n    .attr(\"opacity\", 0.4)\n    .attr(\"x\", function(d,i){ return (width / 3 * i) + ((width/6)-50)})\n    .attr(\"y\", d =&gt; height)\n    .attr('rx', 5)\n    .attr('z', -100)\n    .attr(\"height\", 22)\n    .attr(\"width\", 100)\n    \n  .join('g')\n\n    svg.append(\"g\")\n    .style(\"font\", \"13px serif\")\n    .style(\"font-weight\", \"bold\")\n    .selectAll(\"text\")\n    .data(Object.keys(colorAxisLabels))\n    .attr(\"class\", \"legend-item\")\n    .join(\"text\")\n    .attr(\"x\", function(d,i){ return (width / 3 * i) + (width/6)})\n    .attr(\"y\", d =&gt; height+10)\n    .attr(\"dy\", \"0.35em\")\n    .attr(\"text-anchor\", \"middle\")\n    .text(d =&gt; colorAxisLabels[d])\n\n\n  svg.append(\"g\")\n    .style(\"font\", \"13px serif\")\n    .style(\"font-weight\", \"bold\")\n    .selectAll(\"text\")\n    .data(nodes)\n    .join(\"text\")\n    .attr(\"x\", d =&gt; d.x0 &lt; width / 2 ? d.x1 + 6 : d.x0 - 6)\n    .attr(\"y\", d =&gt; -10)\n    .attr(\"dy\", \"0.35em\")\n    .attr(\"text-anchor\", d =&gt; d.key == 'origin' || d.key == 'events' ? \"middle\" :  d.key == 'dates' ? \"start\": \"end\" )\n    .text(d =&gt; axis_name[d.key])\n\n  svg.append(\"g\")\n    .style(\"font\", \"10px sans-serif\")\n    .selectAll(\"text\")\n    .data(nodes)\n    .join(\"text\")\n    .attr(\"x\", d =&gt; d.x0 &lt; width / 2 ? d.x1 + 6 : d.x0 - 6)\n    .attr(\"y\", d =&gt; (d.y1 + d.y0) / 2)\n    .attr(\"dy\", \"0.35em\")\n    .attr(\"text-anchor\", d =&gt; d.x0 &lt; width / 2 ? \"start\" : \"end\")\n    .text(d =&gt; d.name)\n    .append(\"tspan\")\n    .attr(\"fill-opacity\", 0.7)\n    .text(d =&gt; ` ${d.value.toLocaleString()}`);\n\n  return svg.node();\n}\n\n\n\n\n\n\n\nThe parallel sets offer an interactive visualization: by hovering over the various curved sections, the reader can appreciate how specific dimensions correlate in the database. This screenshot shows that by hovering on the yellow fine curved line in the last panel, you see that there are twelve women in the database for whom we have both birth and death dates, who had entries in the original Dictionary, and who are among the 2% of travelers for whom we have data for between 26 and 74 visits during their journeys.\n Raagavi in a data analysis and visualization session discussing an early version of the parallel sets visualization with digital design professor Michele Graffieti, who visited CESTA last spring from DensityDesign Lab at the Italian Politecnico University of Milan—the best work happens collaboratively!"
  },
  {
    "objectID": "editions/2023/know-systemic-racism/index.html",
    "href": "editions/2023/know-systemic-racism/index.html",
    "title": "Know Systemic Racism",
    "section": "",
    "text": "Know Systemic Racism, the creation of Felicia Smith, Stanford’s inaugural Racial Justice and Social Equity Librarian, aims to “humanize the harm” against Black people in California by focusing on interconnections of discriminatory systems that have been shaped by racist policies and practices of individuals and institutions across centuries. This summer, Felicia Smith is collaborating with Nicole Coleman, Digital Research Architect for the Stanford University Libraries and Research Director for Humanities+Design at CESTA. The summer 2023 project for Know Systemic Racism Data Lab is “Know More Names,” a data curation and public information discovery environment that uses names of people, places, events, and objects as an entry point to reveal connections between harmful and racist policies and practices in California. The goal of this first iteration of “Know More Names” is to enable citizens, activists, journalists, and lawmakers to discover, use, and contribute to factual data that connects legislation, law enforcement policy, the use of military equipment in policing, and deaths that occur through police interaction in California. The focus on policing and race is not the end goal of the project, but a starting point that reflects the origins of the Stanford Libraries’ Know Systemic Racism project in response to the death of George Floyd and the attention to Floyd’s death brought to the connections between the history of policing and race in this country. The students have worked with library catalogers, archivists and data scientists, community activists, and the Stanford Center for Racial Justice to bring this project together."
  },
  {
    "objectID": "editions/2023/know-systemic-racism/index.html#project-description",
    "href": "editions/2023/know-systemic-racism/index.html#project-description",
    "title": "Know Systemic Racism",
    "section": "",
    "text": "Know Systemic Racism, the creation of Felicia Smith, Stanford’s inaugural Racial Justice and Social Equity Librarian, aims to “humanize the harm” against Black people in California by focusing on interconnections of discriminatory systems that have been shaped by racist policies and practices of individuals and institutions across centuries. This summer, Felicia Smith is collaborating with Nicole Coleman, Digital Research Architect for the Stanford University Libraries and Research Director for Humanities+Design at CESTA. The summer 2023 project for Know Systemic Racism Data Lab is “Know More Names,” a data curation and public information discovery environment that uses names of people, places, events, and objects as an entry point to reveal connections between harmful and racist policies and practices in California. The goal of this first iteration of “Know More Names” is to enable citizens, activists, journalists, and lawmakers to discover, use, and contribute to factual data that connects legislation, law enforcement policy, the use of military equipment in policing, and deaths that occur through police interaction in California. The focus on policing and race is not the end goal of the project, but a starting point that reflects the origins of the Stanford Libraries’ Know Systemic Racism project in response to the death of George Floyd and the attention to Floyd’s death brought to the connections between the history of policing and race in this country. The students have worked with library catalogers, archivists and data scientists, community activists, and the Stanford Center for Racial Justice to bring this project together."
  },
  {
    "objectID": "editions/2023/know-systemic-racism/index.html#visualizing-data-about-the-militarization-of-police-by-tracy-wei",
    "href": "editions/2023/know-systemic-racism/index.html#visualizing-data-about-the-militarization-of-police-by-tracy-wei",
    "title": "Know Systemic Racism",
    "section": "Visualizing Data About the Militarization of Police by Tracy Wei",
    "text": "Visualizing Data About the Militarization of Police by Tracy Wei\nAs a research intern for Know Systemic Racism, I built a wireframe and coded a web-based application that makes the military equipment inventory of California law enforcement agencies visible to legislators and citizens. My work directly contributes to a project with the Electronic Frontier Foundation and American Friends Service Committee that demonstrates the militarization of police using records of military equipment. My initial task involved designing a wireframe in Figma for the web application, which would be used as a foundation for the rest of the project. This wireframe included a map view page for users to filter and select specific law enforcement agencies to learn more details about their respective inventories. It also included a gallery view of military equipment that filters inventory by where the user lives so that users can learn more about the military equipment in their local law enforcement agencies and how much money is being put towards these equipment.\nIn order to gather data on the military equipment of law enforcement agencies, I examined policy manuals to record the equipment owned by law enforcement agencies and the associated costs. The web application was developed using Streamlit, which supports data-driven web applications coded in the programming language Python. I used the equipment list to create a table view that showcases all the equipment with details including manufacturer, cost and images. To help users look for specific categories of military equipment and certain companies, I added dropdown menus that allow the user to filter the inventory based on certain criteria. Using the Plotly library, I also built a map view of California with its counties colored by population, and its law enforcement agencies as points on the map, with the goal of displaying the data and military inventory of these law enforcement agencies on an individual level. The project’s next steps are to create data visualizations for the quantity and cost of military equipment for both individual law enforcement agencies and the aggregate law enforcement system."
  },
  {
    "objectID": "editions/2023/know-systemic-racism/index.html#from-data-exploration-to-presentation-by-anabelle-colmenares",
    "href": "editions/2023/know-systemic-racism/index.html#from-data-exploration-to-presentation-by-anabelle-colmenares",
    "title": "Know Systemic Racism",
    "section": "From Data Exploration to Presentation by Anabelle Colmenares",
    "text": "From Data Exploration to Presentation by Anabelle Colmenares\nThis summer, the KSR focused on four datasets: fatal encounters with the police in the United States, data about law enforcement agencies (LEAs) in California, policy manuals of these LEAs, and military equipment policies of these LEAs. To explore these datasets, I first created a platform for KSR to share their data projects. Second, I created pipelines for data extraction and visualization. Finally, I created a website that tied all of the datasets together.\nWe started the data exploration process by creating a data website for all of KSR’s data-related projects in order to have a platform where we could quickly display and share coding projects. I did this by integrating GitHub Pages, Quarto, and GitHub Action, giving us the ability to easily update the website and render code.\nAfter this, my next set of tasks involved establishing pipelines for data visualization, analysis, and extraction. I experimented with different visualization libraries, such as Plotly, Observable Plot, and others, to see which would be better suited for our needs. I also experimented with pulling data from Google Sheets and Wikidata. Pulling data directly from Google Sheets is essential for us because much of the data we use is created by activist groups, and such groups often store data in Google Sheets. Likewise, Wikidata is a community-constructed data source, which we entered data into and want to pull from in order to create applications and visualizations.\nFinally, we decided to build a web application. This web application fulfilled two main objectives: to integrate the 4 main aforementioned datasets and make this information accessible to the common public. We decided this application would have four main information sections corresponding to the four datasets. Within each section, there will be an information card for each entity (for instance, the “Law Enforcement Agencies” section will include information cards for each LEA within California). If there is data within an information card that is tied to another section, clicking on this data will take you to their information pages. For instance, clicking on a particular military equipment item within the information card of a LEA will take you to the page within our website of that military equipment. With all of this, we aim to empower people with a more concentrated and accessible version of this information."
  },
  {
    "objectID": "editions/2023/know-systemic-racism/index.html#data-visualizations",
    "href": "editions/2023/know-systemic-racism/index.html#data-visualizations",
    "title": "Know Systemic Racism",
    "section": "Data Visualizations",
    "text": "Data Visualizations\nBelow are some of the notable table and visualizations that we generated through the internship. These tables and visualizations are generated using the Fatal Encounters Dataset from fatalencounters.org. As seen in the bar charts, this dataset ranges from 2000-2021.\n\nMapping Fatal Encounters\n\nEntire U.S.\n\n\n\n\n\n\n\n\n\n                                                \n\n\n\n\nCalifornia only\n\n\n\n                                                \n\n\n\n\n\nPreliminary FE Data Visualizations\n\nEntire U.S.\nThe plot below visualizes the number of fatal encounters per year for all of the United States.\n\n\nCode\nabbreviated_states_obj = ({\n  AL: 'Alabama',\n  AK: 'Alaska' ,\n  AS: 'American Samoa',\n  AZ: 'Arizona',\n  AR: 'Arkansas',\n  CA: 'California',\n  CO: 'Colorado',\n  CT: 'Connecticut',\n  DE: 'Delaware',\n  DC: 'District of Columbia',\n  FL: 'Florida',\n  GA: 'Georgia',\n  GU: 'Guam',\n  HI: 'Hawaii',\n  ID: 'Idaho',\n  IL: 'Illinois',\n  IN: 'Indiana',\n  IA: 'Iowa',\n  KS: 'Kansas',\n  KY: 'Kentucky',\n  LA: 'Louisiana',\n  ME: 'Maine',\n  MD: 'Maryland',\n  MA: 'Massachusetts',\n  MI: 'Michigan',\n  MN: 'Minnesota',\n  MS: 'Mississippi',\n  MO: 'Missouri',\n  MT: 'Montana',\n  NE: 'Nebraska',\n  NV: 'Nevada',\n  NH: 'New Hampshire',\n  NJ: 'New Jersey',\n  NM: 'New Mexico',\n  NY: 'New York',\n  NC: 'North Carolina',\n  ND: 'North Dakota',\n  OH: 'Ohio',\n  OK: 'Oklahoma',\n  OR: 'Oregon',\n  PA: 'Pennsylvania',\n  PR: 'Puerto Rico',\n  RI: 'Rhode Island',\n  SC: 'South Carolina',\n  SD: 'South Dakota',\n  TN: 'Tennessee',\n  TX: 'Texas',\n  UT: 'Utah',\n  VT: 'Vermont',\n  VI: 'Virgin Islands',\n  VA: 'Virginia',\n  WA: 'Washington',\n  WV: 'West Virginia',\n  WI: 'Wisconsin',\n  WY: 'Wyoming',\n})\ntidy_w_race = transpose(fe_data).map(d =&gt; ({date: new Date(d[' Date of injury resulting in death (month/day/year)']).getFullYear(), count: 1, raceImputed: d['Race with imputations'], race: d.Race, state: abbreviated_states_obj[d.State]}))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nviewof race_imputed = Inputs.radio(new Map([[\"Race with imputations\", 'raceImputed'], [\"Race with no imputations\", 'race']]), {value: 'raceImputed', label: \"Race imputed?\"})\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot({\n  width: 928,\n  height: 500,\n  x: {tickFormat: \"\"},\n  y: {tickSpacing: 50},\n  color: {legend: true},\n  marks: [\n  Plot.barY(tidy_w_race, {x: 'date', y: 'count', fill: race_imputed, sort: race_imputed}),\n  ]\n})\n\n\n\n\n\n\n\n\n\nFor more visualizations, visit https://know-systemic-racism.github.io/fe-search-viz.html"
  }
]